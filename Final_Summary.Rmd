---
title: "Brain Stroke Prediction"
author: "Team Sage"
date: "`r Sys.Date()`"
output:  
    rmdformats::readthedown:
      toc_float: true
      number_sections: true
      
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(scipen = 999,  digits = 3, big.mark=",", warn = -1)
```

```{r basicfunct, include=FALSE}
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

# 1. Introduction
This paper continues our discussion on [Brain Stroke Prediction](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset). Stroke is one of the leading causes of death and disability in the USA. Given this context our basic SMART question remains the same: What are the most accurate predictors of the likelihood of having a brain stroke? This results to be a classification problem on the target variable of having a stroke, and we will apply 3 different approaches and imbalance techniques learned throughout the course to try to solve it.

Included in our discussion is some Exploratory Data Analysis (EDA) from our first assignment, along with some new models, including Logistic Regression, Decision Tree Classifier, and Random Forest Classifier.

# 2. EDA
The following are excerpts and graphs from the EDA section of our previous report. We are including them here to remind the reader of our dataset's attributes, before we dive into the analysis.

```{r basic_libraries, include=FALSE}
library(ggplot2)
library(gridExtra)
library(corrplot)
library(ROSE)
library(dplyr)
library(smotefamily)
library(caTools)
library(randomForest)
library(rpart)
library(rpart.plot)
library("pROC")
```

```{r load_csv, include=FALSE}
stroke_df = read.csv("healthcare-dataset-stroke-data.csv")
```

```{r desc, include=TRUE}
str(stroke_df)
```

```{r data_cleaning, include=FALSE}
stroke_df = subset(stroke_df, select = -c(id))
# converting the numeric variables to factor variables
stroke_df$gender = as.factor(stroke_df$gender)
stroke_df$hypertension = as.factor(stroke_df$hypertension)
stroke_df$heart_disease = as.factor(stroke_df$heart_disease)
stroke_df$ever_married = as.factor(stroke_df$ever_married)
stroke_df$bmi = as.numeric(stroke_df$bmi)
stroke_df$stroke = as.factor(stroke_df$stroke)
stroke_df$work_type = as.factor(stroke_df$work_type)
stroke_df$Residence_type = as.factor(stroke_df$Residence_type)
stroke_df$smoking_status = as.factor(stroke_df$smoking_status)
# To get the summary statistics of the dataset
summary(stroke_df)
```

```{r find_na_fix, include=FALSE}
# To find the NA's in the dataset
paste("The NA's in the dataset is:",sum(is.na(stroke_df)))
```

```{r na_fix, include=FALSE}
# Replacing NA values with average BMI value
stroke_df$bmi[is.na(stroke_df$bmi)] = mean(stroke_df$bmi,na.rm = TRUE)
paste("The NA's in the dataset after imputation of BMI with mean is:",sum(is.na(stroke_df)))
```

```{r summary_after_cleaning, include=FALSE}
# since we had only 1 data point in others category for gender we are removing it
stroke_df = subset(stroke_df,gender!="Other")
summary(stroke_df)
```

```{r subsets, include=FALSE}
# subsetting the data for various analyses 
stroke_1 = subset(stroke_df, stroke == 1)
stroke_0 = subset(stroke_df, stroke == 0)
stroke_1_female = subset(stroke_df, stroke == 1 & gender == "Female")
stroke_1_male = subset(stroke_df, stroke == 1 & gender == "Male")
# creating different columns for bmi, age and average_glucose_level based on different bucketing for each variables
dat <- within(stroke_df, {   
  bmi.cat = NA # need to initialize variable
  bmi.cat[bmi < 18.5] = "underweight"
  bmi.cat[bmi >= 18.5 & bmi < 25] = "normal"
  bmi.cat[bmi >= 25 & bmi < 30] = "overweight"
  bmi.cat[bmi >= 30 & bmi < 40] = "obesity"
  bmi.cat[bmi >=40] = "severe obesity" 
  avg_gluc.cat = NA # need to initialize variable
  avg_gluc.cat[avg_glucose_level < 60] = "Below 60"
  avg_gluc.cat[avg_glucose_level >= 60 & avg_glucose_level < 90] = "60 - 90"
  avg_gluc.cat[avg_glucose_level >= 90 & avg_glucose_level < 120] = "90 - 120"
  avg_gluc.cat[avg_glucose_level >= 120 & avg_glucose_level < 180] = "120 - 180"
  avg_gluc.cat[avg_glucose_level >= 180 & avg_glucose_level < 273] = "180 - 273"
  age.cat = NA
  age.cat[age<=20] = "Under 20"
  age.cat[age>=21 & age<= 40 ] = "20-40"
  age.cat[age>=41 & age<= 60 ] = "40-60"
  age.cat[age>=61 & age<= 80 ] = "60-80"
  age.cat[age>=80 ] = "above 80"
   } )
dat$bmi.cat<- factor(dat$bmi.cat,levels= c("underweight","normal","overweight","obesity","severe obesity" ))
dat$avg_gluc.cat<- factor(dat$avg_gluc.cat,levels= c("Below 60","60 - 90","90 - 120","120 - 180","180 - 273" ))
dat$age.cat<- factor(dat$age.cat,levels= c("Under 20","20-40","40-60","60-80","above 80"))
dat$avg_gluc.cat = as.numeric(factor(dat$avg_gluc.cat))
dat$bmi.cat = as.numeric(factor(dat$bmi.cat))
dat$age.cat = as.numeric(factor(dat$age.cat))
dat$avg_gluc.cat = factor(dat$avg_gluc.cat)
dat$bmi.cat = factor(dat$bmi.cat)
dat$age.cat = factor(dat$age.cat)
str(dat)
```

```{r numerical_variable_dist, include=FALSE}
ggplot(stroke_df, aes(x=age)) +  geom_density(fill="skyblue", color="skyblue", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for age")
ggplot(stroke_df, aes(x=bmi)) +  geom_density(fill="pink", color="pink", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for BMI")
ggplot(stroke_df, aes(x=avg_glucose_level)) +  geom_density(fill="lightgreen", color="lightgreen", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for Average Glucose Level")
```

Out of 5110 observations, we can see there are 4860 no stroke observations, while there are 250 stroke observations.

```{r target_var, include=TRUE}
#library(dplyr)
#stroke_df %>% count(stroke)
ggplot(stroke_df, aes(x=stroke,fill=stroke))+geom_bar()+ggtitle("Distribution of Target variable (Stroke)")+ theme_bw() + theme()+ xlab("Stroke") + ylab("Count of people")
```

## 2.1 Important Features Comparisions

```{r age_bmi, include=TRUE}
ggplot(stroke_1, aes(x=bmi, y=age, color=stroke))+geom_point(size=3)+ ggtitle("Scatter plot for age vs bmi for people who had a stroke")
```
From the scatterplot it is evident that most of the data points fall between the BMI range of 25-35 which is categorized as overweight and obese.

```{r age_hypertension, include=TRUE}
ggplot(data = stroke_df, aes(x=as.character(hypertension), y=age, fill=hypertension)) +
    geom_boxplot() +
    labs(title="Age distribution by hypertension", x="hypertension", y="age")
```

From the boxplot we can see that as age increases the chances of having Hypertension also increases, which can lead to an individual having a stroke.

#  Modeling Techniques

## Addressing the imbalance issue in the dataset
A dataset is said to be imbalanced when the number of observations per class is not equally distributed among the training dataset. There has been a heavy class imbalance in our dataset as mentioned above.

To reduce the imbalance dataset two sampling methods were performed. They are:

**ROSE (Random OverSampler Examples)**

**SMOTE (Synthetic Minority Oversampling Technique)**

##  SMOTE

SMOTE technique involves creating a new dataset by oversampling observations from the minority class, which produces a dataset that has more balanced classes.

```{r,include=TRUE}
set.seed(80)
# In the train data we are using under and oversampling to address the class imbalance problem
ind <- sample(2, nrow(stroke_df), replace = TRUE, prob = c(0.7, 0.3))
train <- stroke_df[ind==1,]
test <- stroke_df[ind==2,]
train <- ovun.sample(stroke~., data=train, method = "both",p = 0.5,seed = 222)$data
r<-table(train$stroke)
```

## Feature Selection

```{r}
clf = randomForest(x = train[-11],
                             y = train$stroke,
                             ntree = 500)

# Predicting the Test set results
y_pred = predict(clf, newdata = test[-11])

# Confusion Matrix
confusion = table(test$stroke, y_pred)
varImpPlot(clf)

```
Random forest model is considered for feature selection. It consists of 4-12 hundred trees, each of them built over a random extraction of the characteristics within the dataset, and a random extraction of the features. Because some trees don't see all the features or all the observations, the trees are guaranteed to be de-correlated and consequently less likely to overfit. Every tree also consists of a series of yes-or-no questions depending on a single or several attributes. The dataset is split into two buckets at each node by the tree, with each bucket containing observations that are more similar to one another and distinct from those in the other bucket. The significance of each attribute is therefore determined by how "pure" each of the buckets is.

### Logistic Regression - SMOTE

Logit is a type of generalized linear model (GLiM) that uses statistical analysis to predict an event based on known factors when using a dichotomous dependent variable. In the logit model the log odds of the outcome is modeled as a linear combination of the predictor variables.

```{r, include=T}
set.seed(123)
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=train)
predlogitrose <- predict(logitrose, newdata=test[-11], type="response")
confusion <- table(test$stroke, predlogitrose >= 0.5)
confusion
# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
recall_score =(TP)/(TP+FN)
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
test_prob = predict(logitrose, test[-11], type = "response")
```

```{r, include = TRUE}
test_roc = roc(test$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
test_roc
```

```{r, include=T}
print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```



### Logistic Regression with feature selected variables - SMOTE


```{r,include=F}
set.seed(1234)
train_fe = subset(train, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
test_fe = subset(test, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))

```

```{r,include=T}
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=train_fe)
predlogitrose <- predict(logitrose, newdata=test_fe[-7], type="response")
confusion <- table(test_fe$stroke, predlogitrose >= 0.5)


TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


test_prob = predict(logitrose, test_fe[-7], type = "response")
test_roc = roc(test_fe$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
test_roc



print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```

### Decision Tree - SMOTE
Decision Trees are versatile machine learning algorithm that carry out both classification and regression tasks. They are extremely powerful algorithms that can successfully fit complex datasets.


```{r}
fit <- rpart(stroke~ ., data = train , method = 'class')
rpart.plot(fit, extra = 106)
```

```{r,include=T}
predict_unseen <-predict(fit, test[-11], type = 'class')
confusion <- table(test$stroke, predict_unseen)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))



```
### Decision Tree with Feature Selection - SMOTE

```{r,include=T}
fit <- rpart(stroke~ ., data = train_fe , method = 'class')
rpart.plot(fit, extra = 106)
```


```{r,include=T}

predict_unseen <-predict(fit, test_fe[-7], type = 'class')
confusion <- table(test_fe$stroke, predict_unseen)
# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)



print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))

```

### Tuned Decision Tree - SMOTE 

Decision tree in R has various parameters that control aspects of the fit. In rpart decision tree library, we can control the parameters using the rpart.control() function. In the following code we have introduced the parameters that need to be tuned.

```{r,include=F}
control <- rpart.control(minsplit = 5,
    minbucket = round(5 / 3),
    maxdepth = 6,
    cp = 0)
tune_fit <- rpart(stroke~., data = train , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
```


```{r,include=T}
predict_unseen1 <-predict(tune_fit, test[-11], type = 'class')
confusion <- table(test$stroke, predict_unseen1)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)




print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```

### Tuned Decision Tree with Feature Selection - SMOTE

```{r}
control <- rpart.control(minsplit = 5,
    minbucket = round(5 / 3),
    maxdepth = 6,
    cp = 0)
tune_fit <- rpart(stroke~., data = train_fe , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
```


```{r,include=T}
predict_unseen1 <-predict(tune_fit, test_fe[-7], type = 'class')
confusion <- table(test_fe$stroke, predict_unseen1)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)



print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```


### Random Forest 
Random Forest is a collection of decision trees. To obtain more precise predictions, it constructs and merges several decision trees. The classification algorithm is non-linear. When utilized independently, each decision tree model is used.



```{r,include=F}
classifier_RF = randomForest(x = train[-11],
                             y = train$stroke,
                             ntree = 500)
  
classifier_RF
```

```{r,include=T}
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test[-11])
# Confusion Matrix
confusion = table(test$stroke, y_pred)
# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))

varImpPlot(classifier_RF)
```

### Random Forest with Feature Selected Variables 

```{r,include=F}
classifier_RF1 = randomForest(x = train_fe[-7],
                             y = train_fe$stroke,
                             ntree = 500)
classifier_RF1
```

```{r,include=T}
# Predicting the Test set results
y_pred = predict(classifier_RF1, newdata = test_fe[-7])
# Confusion Matrix
confusion = table(test_fe$stroke, y_pred)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))

varImpPlot(classifier_RF1)
```



## ROSE 
ROSE is Random Over Sampling Examples. It expands the feature space of minority and majority class examples to provide a sample of synthetic data. Operationally, a conditional kernel density estimate of the two classes is used to generate the new samples.

```{r}
set.seed(1234)
trainIndex = sample(1:nrow(stroke_df), size=round(0.75*nrow(stroke_df)), replace=FALSE)
train1 <- stroke_df[trainIndex,]
test1  <- stroke_df[-trainIndex,]

```

 
```{r,include=F}
library(ROSE)
set.seed(1234)
train_fe = subset(train1, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
test1_fe = subset(test1, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
str(train_fe)
dim(test1_fe)
```


```{r,include=F}
set.seed(1234)
trainrose1<-ROSE(stroke~.,data=train_fe)$data
```


```{r}
set.seed(1234)
trainrose<-ROSE(stroke~.,data=train1)$data

```
```{r}
trainrose$age = abs(trainrose$age)
trainrose$avg_glucose_level = abs(trainrose$avg_glucose_level)

```


```{r}
trainrose1$age = abs(trainrose1$age)
trainrose1$avg_glucose_level = abs(trainrose1$avg_glucose_level)

```

### Logistic Regression - ROSE


```{r,include=T}
set.seed(1234)
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=trainrose)
predlogitrose <- predict(logitrose, newdata=test1[-11], type="response")
confusion <- table(test1$stroke, predlogitrose >= 0.5)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)



print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))


test_prob = predict(logitrose, test1[-11], type = "response")
test_roc = roc(test1$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
test_roc
```


### Logistic Regression with Feature Selection - ROSE 


```{r}
set.seed(1234)
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=trainrose1)
predlogitrose <- predict(logitrose, newdata=test1_fe[-7], type="response")
confusion <- table(test1_fe$stroke, predlogitrose >= 0.5)
confusion
# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))


test_prob = predict(logitrose, test1_fe[-11], type = "response")
test_roc = roc(test1_fe$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
```


### DECISION TREE - ROSE

```{r,include=F}
fit <- rpart(stroke~ . , data = trainrose , method = 'class')
rpart.plot(fit, extra = 106)
```


```{r,include=T}
predict_unseen <-predict(fit, test1[-11], type = 'class')
confusion <- table(test1$stroke, predict_unseen)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
FPR = FP/(FP+TN)
TPR = (TP)/(TP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```

### DECISION TREE with Feature Selection - ROSE
 
```{r}
fit <- rpart(stroke~ . , data = trainrose1 , method = 'class')
rpart.plot(fit, extra = 106)
```


```{r}
predict_unseen <-predict(fit, test1_fe[-7], type = 'class')
confusion <- table(test1_fe$stroke, predict_unseen)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```


### Tuned Decision Tree - ROSE

```{r,include=T}

control <- rpart.control(minsplit = 7,
    minbucket = round(5 / 3),
    maxdepth = 4,
    cp = 0)

tune_fit <- rpart(stroke~., data = trainrose , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
predict_unseen1 <-predict(tune_fit, test1, type = 'class')
confusion <- table(test1$stroke, predict_unseen1)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```


### Tuned Decision Tree with Feature Selection - ROSE 

```{r,include=F}
control <- rpart.control(minsplit = 7,
    minbucket = round(5 / 3),
    maxdepth = 4,
    cp = 0)
tune_fit <- rpart(stroke~., data = trainrose1 , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
predict_unseen1 <-predict(tune_fit, test1_fe, type = 'class')
confusion <- table(test1_fe$stroke, predict_unseen1)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```

### Random Forest 

```{r,include=F}
classifier_RF = randomForest(x = trainrose[-11],
                             y = trainrose$stroke,
                             ntree = 500)
  
classifier_RF
```

```{r,include=T}

# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test1[-11])
# Confusion Matrix
confusion = table(test1$stroke, y_pred)
# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```

### Random Forest with feature selection 

```{r,include=F}
classifier_RF = randomForest(x = trainrose1[-7],
                             y = trainrose1$stroke,
                             ntree = 500)
  
classifier_RF
```

```{r,include=T}
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test1_fe[-7])
# Confusion Matrix
confusion = table(test1_fe$stroke, y_pred)

# Eval Metric
TN =confusion[1,1]
TP =confusion[2,2]
FP =confusion[1,2]
FN =confusion[2,1]
precision =(TP)/(TP+FP)
recall_score =(TP)/(TP+FN)
f1_score=2*((precision*recall_score)/(precision+recall_score))
accuracy_model  =(TP+TN)/(TP+TN+FP+FN)


print(paste('Accuracy for test', accuracy_model))
print(paste('recall_score for test', recall_score))
```



