ROC_rf <- roc(test1$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# random forest classifier
classifier_RF = randomForest(x = trainrose1[-7],
y = trainrose1$stroke,
ntree = 500)
classifier_RF
# random forest classifier
classifier_RF = randomForest(x = trainrose1[-7],
y = trainrose1$stroke,
ntree = 500)
classifier_RF
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test1_fe[-7])
# Evaluation Metric
confusion1= confusionMatrix(y_pred,test1_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(classifier_RF,test1_fe[-7],type="prob")
ROC_rf <- roc(test1_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test1_fe[-7])
# Evaluation Metric
confusion1= confusionMatrix(y_pred,test1_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(classifier_RF,test1_fe[-7],type="prob")
ROC_rf <- roc(test1_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
knitr::opts_chunk$set(echo = FALSE)
options(scipen = 999,  digits = 3, big.mark=",", warn = -1)
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
library(ggplot2)
library(gridExtra)
library(corrplot)
library(ROSE)
library(dplyr)
library(smotefamily)
library(caTools)
library(randomForest)
library(rpart)
library(rpart.plot)
library("pROC")
library(caret)
stroke_df = read.csv("healthcare-dataset-stroke-data.csv")
str(stroke_df)
stroke_df = subset(stroke_df, select = -c(id))
# converting the numeric variables to factor variables
stroke_df$gender = as.factor(stroke_df$gender)
stroke_df$hypertension = as.factor(stroke_df$hypertension)
stroke_df$heart_disease = as.factor(stroke_df$heart_disease)
stroke_df$ever_married = as.factor(stroke_df$ever_married)
stroke_df$bmi = as.numeric(stroke_df$bmi)
stroke_df$stroke = as.factor(stroke_df$stroke)
stroke_df$work_type = as.factor(stroke_df$work_type)
stroke_df$Residence_type = as.factor(stroke_df$Residence_type)
stroke_df$smoking_status = as.factor(stroke_df$smoking_status)
# To get the summary statistics of the dataset
summary(stroke_df)
# To find the NA's in the dataset
paste("The NA's in the dataset is:",sum(is.na(stroke_df)))
# Replacing NA values with average BMI value
stroke_df$bmi[is.na(stroke_df$bmi)] = mean(stroke_df$bmi,na.rm = TRUE)
paste("The NA's in the dataset after imputation of BMI with mean is:",sum(is.na(stroke_df)))
# since we had only 1 data point in others category for gender we are removing it
stroke_df = subset(stroke_df,gender!="Other")
summary(stroke_df)
# subsetting the data for various analyses
stroke_1 = subset(stroke_df, stroke == 1)
stroke_0 = subset(stroke_df, stroke == 0)
stroke_1_female = subset(stroke_df, stroke == 1 & gender == "Female")
stroke_1_male = subset(stroke_df, stroke == 1 & gender == "Male")
# creating different columns for bmi, age and average_glucose_level based on different bucketing for each variables
dat <- within(stroke_df, {
bmi.cat = NA # need to initialize variable
bmi.cat[bmi < 18.5] = "underweight"
bmi.cat[bmi >= 18.5 & bmi < 25] = "normal"
bmi.cat[bmi >= 25 & bmi < 30] = "overweight"
bmi.cat[bmi >= 30 & bmi < 40] = "obesity"
bmi.cat[bmi >=40] = "severe obesity"
avg_gluc.cat = NA # need to initialize variable
avg_gluc.cat[avg_glucose_level < 60] = "Below 60"
avg_gluc.cat[avg_glucose_level >= 60 & avg_glucose_level < 90] = "60 - 90"
avg_gluc.cat[avg_glucose_level >= 90 & avg_glucose_level < 120] = "90 - 120"
avg_gluc.cat[avg_glucose_level >= 120 & avg_glucose_level < 180] = "120 - 180"
avg_gluc.cat[avg_glucose_level >= 180 & avg_glucose_level < 273] = "180 - 273"
age.cat = NA
age.cat[age<=20] = "Under 20"
age.cat[age>=21 & age<= 40 ] = "20-40"
age.cat[age>=41 & age<= 60 ] = "40-60"
age.cat[age>=61 & age<= 80 ] = "60-80"
age.cat[age>=80 ] = "above 80"
} )
dat$bmi.cat<- factor(dat$bmi.cat,levels= c("underweight","normal","overweight","obesity","severe obesity" ))
dat$avg_gluc.cat<- factor(dat$avg_gluc.cat,levels= c("Below 60","60 - 90","90 - 120","120 - 180","180 - 273" ))
dat$age.cat<- factor(dat$age.cat,levels= c("Under 20","20-40","40-60","60-80","above 80"))
dat$avg_gluc.cat = as.numeric(factor(dat$avg_gluc.cat))
dat$bmi.cat = as.numeric(factor(dat$bmi.cat))
dat$age.cat = as.numeric(factor(dat$age.cat))
dat$avg_gluc.cat = factor(dat$avg_gluc.cat)
dat$bmi.cat = factor(dat$bmi.cat)
dat$age.cat = factor(dat$age.cat)
str(dat)
ggplot(stroke_df, aes(x=age)) +  geom_density(fill="skyblue", color="skyblue", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for age")
ggplot(stroke_df, aes(x=bmi)) +  geom_density(fill="pink", color="pink", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for BMI")
ggplot(stroke_df, aes(x=avg_glucose_level)) +  geom_density(fill="lightgreen", color="lightgreen", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for Average Glucose Level")
#library(dplyr)
#stroke_df %>% count(stroke)
ggplot(stroke_df, aes(x=stroke,fill=stroke))+geom_bar()+ggtitle("Distribution of Target variable (Stroke)")+ theme_bw() + theme()+ xlab("Stroke") + ylab("Count of people")
ggplot(stroke_1, aes(x=bmi, y=age, color=stroke))+geom_point(size=3)+ ggtitle("Scatter plot for age vs bmi for people who had a stroke")
ggplot(data = stroke_df, aes(x=as.character(hypertension), y=age, fill=hypertension)) +
geom_boxplot() +
labs(title="Age distribution by hypertension", x="hypertension", y="age")
set.seed(80)
# In the train data we are using under and oversampling to address the class imbalance problem
ind <- sample(2, nrow(stroke_df), replace = TRUE, prob = c(0.7, 0.3))
train <- stroke_df[ind==1,]
test <- stroke_df[ind==2,]
train <- ovun.sample(stroke~., data=train, method = "both",p = 0.5,seed = 222)$data
r<-table(train$stroke)
clf = randomForest(x = train[-11],
y = train$stroke,
ntree = 500)
# Predicting the Test set results
y_pred = predict(clf, newdata = test[-11])
# Confusion Matrix
confusion = table(test$stroke, y_pred)
varImpPlot(clf)
set.seed(123)
#logistic regression
logit  <- glm(stroke ~., family=binomial (link="logit"), data=train)
# prediction
predlogit <- predict(logit, newdata=test[-11], type="response")
pred = ifelse(predlogit>=0.5,1,0)
pred = as.factor(pred)
# Eval Metric
confusion1 = confusionMatrix(pred,test$stroke,mode= "everything")
confusion1
test_prob = predict(logit, test[-11], type = "response")
# AUC - ROC curve
test_roc = roc(test$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
set.seed(1234)
# selecting the features based on the feature selection done above
train_fe = subset(train, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
test_fe = subset(test, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
# logistic regression model
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=train_fe)
# prediction
predlogit <- predict(logit, newdata=test_fe[-7], type="response")
knitr::opts_chunk$set(echo = FALSE)
options(scipen = 999,  digits = 3, big.mark=",", warn = -1)
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
library(ggplot2)
library(gridExtra)
library(corrplot)
library(ROSE)
library(dplyr)
library(smotefamily)
library(caTools)
library(randomForest)
library(rpart)
library(rpart.plot)
library("pROC")
library(caret)
stroke_df = read.csv("healthcare-dataset-stroke-data.csv")
str(stroke_df)
stroke_df = subset(stroke_df, select = -c(id))
# converting the numeric variables to factor variables
stroke_df$gender = as.factor(stroke_df$gender)
stroke_df$hypertension = as.factor(stroke_df$hypertension)
stroke_df$heart_disease = as.factor(stroke_df$heart_disease)
stroke_df$ever_married = as.factor(stroke_df$ever_married)
stroke_df$bmi = as.numeric(stroke_df$bmi)
stroke_df$stroke = as.factor(stroke_df$stroke)
stroke_df$work_type = as.factor(stroke_df$work_type)
stroke_df$Residence_type = as.factor(stroke_df$Residence_type)
stroke_df$smoking_status = as.factor(stroke_df$smoking_status)
# To get the summary statistics of the dataset
summary(stroke_df)
# To find the NA's in the dataset
paste("The NA's in the dataset is:",sum(is.na(stroke_df)))
# Replacing NA values with average BMI value
stroke_df$bmi[is.na(stroke_df$bmi)] = mean(stroke_df$bmi,na.rm = TRUE)
paste("The NA's in the dataset after imputation of BMI with mean is:",sum(is.na(stroke_df)))
# since we had only 1 data point in others category for gender we are removing it
stroke_df = subset(stroke_df,gender!="Other")
summary(stroke_df)
# subsetting the data for various analyses
stroke_1 = subset(stroke_df, stroke == 1)
stroke_0 = subset(stroke_df, stroke == 0)
stroke_1_female = subset(stroke_df, stroke == 1 & gender == "Female")
stroke_1_male = subset(stroke_df, stroke == 1 & gender == "Male")
# creating different columns for bmi, age and average_glucose_level based on different bucketing for each variables
dat <- within(stroke_df, {
bmi.cat = NA # need to initialize variable
bmi.cat[bmi < 18.5] = "underweight"
bmi.cat[bmi >= 18.5 & bmi < 25] = "normal"
bmi.cat[bmi >= 25 & bmi < 30] = "overweight"
bmi.cat[bmi >= 30 & bmi < 40] = "obesity"
bmi.cat[bmi >=40] = "severe obesity"
avg_gluc.cat = NA # need to initialize variable
avg_gluc.cat[avg_glucose_level < 60] = "Below 60"
avg_gluc.cat[avg_glucose_level >= 60 & avg_glucose_level < 90] = "60 - 90"
avg_gluc.cat[avg_glucose_level >= 90 & avg_glucose_level < 120] = "90 - 120"
avg_gluc.cat[avg_glucose_level >= 120 & avg_glucose_level < 180] = "120 - 180"
avg_gluc.cat[avg_glucose_level >= 180 & avg_glucose_level < 273] = "180 - 273"
age.cat = NA
age.cat[age<=20] = "Under 20"
age.cat[age>=21 & age<= 40 ] = "20-40"
age.cat[age>=41 & age<= 60 ] = "40-60"
age.cat[age>=61 & age<= 80 ] = "60-80"
age.cat[age>=80 ] = "above 80"
} )
dat$bmi.cat<- factor(dat$bmi.cat,levels= c("underweight","normal","overweight","obesity","severe obesity" ))
dat$avg_gluc.cat<- factor(dat$avg_gluc.cat,levels= c("Below 60","60 - 90","90 - 120","120 - 180","180 - 273" ))
dat$age.cat<- factor(dat$age.cat,levels= c("Under 20","20-40","40-60","60-80","above 80"))
dat$avg_gluc.cat = as.numeric(factor(dat$avg_gluc.cat))
dat$bmi.cat = as.numeric(factor(dat$bmi.cat))
dat$age.cat = as.numeric(factor(dat$age.cat))
dat$avg_gluc.cat = factor(dat$avg_gluc.cat)
dat$bmi.cat = factor(dat$bmi.cat)
dat$age.cat = factor(dat$age.cat)
str(dat)
ggplot(stroke_df, aes(x=age)) +  geom_density(fill="skyblue", color="skyblue", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for age")
ggplot(stroke_df, aes(x=bmi)) +  geom_density(fill="pink", color="pink", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for BMI")
ggplot(stroke_df, aes(x=avg_glucose_level)) +  geom_density(fill="lightgreen", color="lightgreen", alpha=0.5)+ theme_bw() + theme()+ ggtitle("Distribution for Average Glucose Level")
#library(dplyr)
#stroke_df %>% count(stroke)
ggplot(stroke_df, aes(x=stroke,fill=stroke))+geom_bar()+ggtitle("Distribution of Target variable (Stroke)")+ theme_bw() + theme()+ xlab("Stroke") + ylab("Count of people")
ggplot(stroke_1, aes(x=bmi, y=age, color=stroke))+geom_point(size=3)+ ggtitle("Scatter plot for age vs bmi for people who had a stroke")
ggplot(data = stroke_df, aes(x=as.character(hypertension), y=age, fill=hypertension)) +
geom_boxplot() +
labs(title="Age distribution by hypertension", x="hypertension", y="age")
set.seed(80)
# In the train data we are using under and oversampling to address the class imbalance problem
ind <- sample(2, nrow(stroke_df), replace = TRUE, prob = c(0.7, 0.3))
train <- stroke_df[ind==1,]
test <- stroke_df[ind==2,]
train <- ovun.sample(stroke~., data=train, method = "both",p = 0.5,seed = 222)$data
r<-table(train$stroke)
clf = randomForest(x = train[-11],
y = train$stroke,
ntree = 500)
# Predicting the Test set results
y_pred = predict(clf, newdata = test[-11])
# Confusion Matrix
confusion = table(test$stroke, y_pred)
varImpPlot(clf)
set.seed(123)
#logistic regression
logit  <- glm(stroke ~., family=binomial (link="logit"), data=train)
# prediction
predlogit <- predict(logit, newdata=test[-11], type="response")
pred = ifelse(predlogit>=0.5,1,0)
pred = as.factor(pred)
# Eval Metric
confusion1 = confusionMatrix(pred,test$stroke,mode= "everything")
confusion1
test_prob = predict(logit, test[-11], type = "response")
# AUC - ROC curve
test_roc = roc(test$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
set.seed(1234)
# selecting the features based on the feature selection done above
train_fe = subset(train, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
test_fe = subset(test, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
# logistic regression model
logit  <- glm(stroke ~., family=binomial (link="logit"), data=train_fe)
# prediction
predlogit <- predict(logit, newdata=test_fe[-7], type="response")
pred = ifelse(predlogit>=0.5,1,0)
pred = as.factor(pred)
# Evaluation Metric
confusion1= confusionMatrix(pred,test_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
test_prob = predict(logit, test_fe[-7], type = "response")
test_roc = roc(test_fe$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
# decision tree fitting
fit <- rpart(stroke~ ., data = train , method = 'class')
rpart.plot(fit, extra = 106)
# prediction
predict_unseen <-predict(fit, test[-11], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen,test$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(fit,test[-11],type="prob")
ROC_rf <- roc(test$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of Decision Tree: ", auc(ROC_rf))
# decision tree fit
fit <- rpart(stroke~ ., data = train_fe , method = 'class')
rpart.plot(fit, extra = 106)
# Prediction
predict_unseen <-predict(fit, test_fe[-7], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen,test_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(fit,test_fe[-7],type="prob")
ROC_rf <- roc(test_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of Decision Tree: ", auc(ROC_rf))
# parameter setting for decision tree
control <- rpart.control(minsplit = 5,
minbucket = round(5 / 3),
maxdepth = 6,
cp = 0)
# fitting the model
tune_fit <- rpart(stroke~., data = train , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
# Prediction
predict_unseen1 <-predict(tune_fit, test[-11], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen1,test$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(tune_fit,test[-11],type="prob")
ROC_rf <- roc(test$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of Decision Tree: ", auc(ROC_rf))
# setting the parameters for the tree
control <- rpart.control(minsplit = 5,
minbucket = round(5 / 3),
maxdepth = 6,
cp = 0)
# fitting the model
tune_fit <- rpart(stroke~., data = train_fe , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
predict_unseen1 <-predict(tune_fit, test_fe[-7], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen1,test_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(tune_fit,test_fe[-7],type="prob")
ROC_rf <- roc(test_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of Decision Tree: ", auc(ROC_rf))
# Random forest classifier
classifier_RF = randomForest(x = train[-11],
y = train$stroke,
ntree = 500)
classifier_RF
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test[-11])
# Evaluation Metric
confusion1= confusionMatrix(y_pred,test$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(classifier_RF,test[-11],type="prob")
ROC_rf <- roc(test$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# Random Forest Classifier
classifier_RF1 = randomForest(x = train_fe[-7],
y = train_fe$stroke,
ntree = 500)
classifier_RF1
# Predicting the Test set results
y_pred = predict(classifier_RF1, newdata = test_fe[-7])
# Evaluation Metric
confusion1= confusionMatrix(y_pred,test_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(classifier_RF1,test_fe[-7],type="prob")
ROC_rf <- roc(test_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# splitting the data into train and test split
set.seed(1234)
trainIndex = sample(1:nrow(stroke_df), size=round(0.75*nrow(stroke_df)), replace=FALSE)
train1 <- stroke_df[trainIndex,]
test1  <- stroke_df[-trainIndex,]
# subsetting the train and test data based on feature selection
set.seed(1234)
train_fe = subset(train1, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
test1_fe = subset(test1, select = c(age,avg_glucose_level,work_type,hypertension,smoking_status,bmi,stroke))
str(train_fe)
dim(test1_fe)
# applying rose sampling to train data which has feature selected variables
set.seed(1234)
trainrose1<-ROSE(stroke~.,data=train_fe)$data
# applying rose sampling to data which has all the variables
set.seed(1234)
trainrose<-ROSE(stroke~.,data=train1)$data
# making sure there are no negative values for data with all variables
trainrose$age = abs(trainrose$age)
trainrose$avg_glucose_level = abs(trainrose$avg_glucose_level)
# making sure there are no negative values for data with feature selected variables
trainrose1$age = abs(trainrose1$age)
trainrose1$avg_glucose_level = abs(trainrose1$avg_glucose_level)
set.seed(1234)
# logistic model
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=trainrose)
# Prediction
predlogitrose <- predict(logitrose, newdata=test1[-11], type="response")
pred = ifelse(predlogitrose>=0.5,1,0)
pred = as.factor(pred)
# Evaluation Metric
confusion1= confusionMatrix(pred,test1$stroke,mode= "everything")
confusion1
# AUC-ROC curve
test_prob = predict(logitrose, test1[-11], type = "response")
test_roc = roc(test1$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
test_roc
set.seed(1234)
# Logistic Model
logitrose  <- glm(stroke ~., family=binomial (link="logit"), data=trainrose1)
# Prediction
predlogitrose <- predict(logitrose, newdata=test1_fe[-7], type="response")
pred = ifelse(predlogitrose>=0.5,1,0)
pred = as.factor(pred)
# Evaluation Metric
confusion1= confusionMatrix(pred,test1_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
test_prob = predict(logitrose, test1_fe[-11], type = "response")
test_roc = roc(test1_fe$stroke ~ test_prob, plot = TRUE, print.auc = TRUE)
fit <- rpart(stroke~ . , data = trainrose , method = 'class')
rpart.plot(fit, extra = 106)
# prediction
predict_unseen <-predict(fit, test1[-11], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen,test1$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(fit,test1[-11],type="prob")
ROC_rf <- roc(test1$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# fitting the decision tree
fit <- rpart(stroke~ . , data = trainrose1 , method = 'class')
rpart.plot(fit, extra = 106)
# prediction
predict_unseen <-predict(fit, test1_fe[-7], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen,test1_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(fit,test1_fe[-7],type="prob")
ROC_rf <- roc(test1_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# setting the parameters for decision tree
control <- rpart.control(minsplit = 7,
minbucket = round(5 / 3),
maxdepth = 4,
cp = 0)
# fitting the tree
tune_fit <- rpart(stroke~., data = trainrose , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
# Prediction
predict_unseen1 <-predict(tune_fit, test1[-11], type = 'class')
# Eval Metric
confusion1= confusionMatrix(predict_unseen1,test1$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(tune_fit,test1[-11],type="prob")
ROC_rf <- roc(test1$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# setting the parameters for decision tree
control <- rpart.control(minsplit = 7,
minbucket = round(5 / 3),
maxdepth = 4,
cp = 0)
# fitting the tree
tune_fit <- rpart(stroke~., data = trainrose1 , method = 'class', control = control)
rpart.plot(tune_fit, extra = 106)
# prediction
predict_unseen1 <-predict(tune_fit, test1_fe[-7], type = 'class')
# Evaluation Metric
confusion1= confusionMatrix(predict_unseen,test1_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(tune_fit,test1_fe[-7],type="prob")
ROC_rf <- roc(test1_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# random forest classifier
classifier_RF = randomForest(x = trainrose[-11],
y = trainrose$stroke,
ntree = 500)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test1[-11])
# Evaluation Metric
confusion1= confusionMatrix(y_pred,test1$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(classifier_RF,test1[-11],type="prob")
ROC_rf <- roc(test1$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
# random forest classifier
classifier_RF = randomForest(x = trainrose1[-7],
y = trainrose1$stroke,
ntree = 500)
classifier_RF
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test1_fe[-7])
# Evaluation Metric
confusion1= confusionMatrix(y_pred,test1_fe$stroke,mode= "everything")
confusion1
# AUC-ROC curve
prob=predict(classifier_RF,test1_fe[-7],type="prob")
ROC_rf <- roc(test1_fe$stroke, prob[,2])
plot(ROC_rf)
paste("Area under curve of random forest: ", auc(ROC_rf))
